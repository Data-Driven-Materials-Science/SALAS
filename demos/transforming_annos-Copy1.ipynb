{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies\n",
    "\n",
    "### Instance Segmentation of Powder Particles and Satellites\n",
    "\n",
    "This example is used to generate a visualization of an individual image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regular module imports\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import skimage.io\n",
    "import sys\n",
    "\n",
    "## detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import (\n",
    "    DatasetCatalog,\n",
    "    MetadataCatalog,\n",
    ")\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.structures import BoxMode\n",
    "#from detectron2.evaluation import coco_evaluation\n",
    "from detectron2.data.datasets.coco import convert_to_coco_json\n",
    "from detectron2.evaluation.coco_evaluation import instances_to_coco_json\n",
    "from detectron2.utils.visualizer import GenericMask\n",
    "import pycocotools.mask as mask_util\n",
    "from skimage import measure\n",
    "from imantics import Polygons, Mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting System Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../'\n",
    "sys.path.append(root)\n",
    "from sat_helpers import data_utils, visualize, export_anno\n",
    "EXPERIMENT_NAME = 'satellite' # can be 'particles' or 'satellite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def flip_save_image(name, horizontally, vertically, save=True):\n",
    "    new_name = name\n",
    "    img_path = Path('Auto_annotate_images', image_name +'.png')\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if horizontally:\n",
    "        new_name += 'x'\n",
    "        img = cv2.flip(img, 1)\n",
    "    if vertically:\n",
    "        new_name += 'y'\n",
    "        img = cv2.flip(img, 0)\n",
    "    new_img_path = Path('Auto_annotate_images', new_name +'.png')\n",
    "    if save:\n",
    "        cv2.imwrite(str(new_img_path), img)\n",
    "    return new_name\n",
    "\n",
    "def invert_list(input_list, list_range):\n",
    "    output_list = []\n",
    "    for i in input_list:\n",
    "        output_list.append(i)\n",
    "    for i in range(len(output_list)):\n",
    "        output_list[i] = list_range - output_list[i]\n",
    "    return output_list\n",
    "\n",
    "\n",
    "\n",
    "def invert_shape(input_dict, img_width, img_height, horizontal, vertical):\n",
    "    if horizontal: \n",
    "        input_dict['shape_attributes']['all_points_x'] = invert_list(input_dict['shape_attributes']['all_points_x'], img_width)\n",
    "    if vertical: \n",
    "        input_dict['shape_attributes']['all_points_y'] = invert_list(input_dict['shape_attributes']['all_points_y'], img_height)\n",
    "    return input_dict\n",
    "\n",
    "\n",
    "def invert_x_y_regions(input_list, img_width, img_height, horizontal, vertical):\n",
    "    output_list = []\n",
    "    for i in input_list:\n",
    "        output_list.append(invert_shape(i, img_width, img_height, horizontal, vertical))\n",
    "    return output_list\n",
    "###TODO: Finish up this method. The name of the image must be changed, including the additional image size\n",
    "###Then these methods must be created for both horizontal and verticle shifts\n",
    "###Create an automated program to create all of the neccesary images and test http://www.learningaboutelectronics.com/Articles/How-to-flip-an-image-horizontally-vertically-in-Python-OpenCV.php#:~:text=To%20horizontally%20flip%20an%20image,1%20(for%20horizontal%20flipping).\n",
    "###Import new docs into VIA and see how they look\n",
    "def flip_and_save(name, horizontally, vertically, save=True):\n",
    "    new_name = name\n",
    "    img_path = Path(root, '..', 'SEM_Images', 'initial_paper_complete_set', name +'.png')\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if horizontally:\n",
    "        new_name += 'X'\n",
    "        img = cv2.flip(img, 1)\n",
    "    if vertically:\n",
    "        new_name += 'Y'\n",
    "        img = cv2.flip(img, 0)\n",
    "    new_img_path = Path(root, '..', 'SEM_Images', 'initial_paper_complete_set', 'geometric', new_name +'.png')\n",
    "    if save:\n",
    "        cv2.imwrite(str(new_img_path), img)\n",
    "    return new_name\n",
    "print('')\n",
    "\n",
    "def color_and_save(name, transformation):\n",
    "    #transformation: 0-1 = darker, 1 = no change, 1+ = lighter\n",
    "    im = Image.open(root + '../SEM_Images/initial_paper_complete_set/geometric/' + name + '.png')\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    factor = transformation\n",
    "    im_output = enhancer.enhance(factor)\n",
    "    name_change = name\n",
    "    if factor < 1:\n",
    "        name_change += 'd'\n",
    "    elif factor > 1: \n",
    "        name_change += 'b'\n",
    "    else:\n",
    "        name_change += 's'\n",
    "    im_output.save(root + '../SEM_Images/initial_paper_complete_set/photometric/' + name_change + '.png')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491805\n",
      "1024 768\n"
     ]
    }
   ],
   "source": [
    "image_name = \"S02_02_SE1_300X18\"\n",
    "img_path = Path(root, 'data', 'SEM', image_name +'.png')\n",
    "image_size = os.path.getsize(img_path)\n",
    "print(image_size)\n",
    "import PIL\n",
    "image = PIL.Image.open(img_path)\n",
    "width, height = image.size\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Annotations\n",
    "Below are procedures to transform annotations to adhere to data augmentation. These transformations will be saved as JSON files. You should take the JSON file and load import it into VIA. From here, load in a couple images just to verify that the satellite locations of annotations are matching the satellite location in the image itself. Add in any settings you wish to have and save as a VIA project. This may now be used as a training file.\n",
    "### Collecting Image Information\n",
    "Knowing the pixel resolution and size of file is imperative towards creating new annotations for augmented images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_train = Path('..', 'data', 'VIA', f'{EXPERIMENT_NAME}_training.json')  # path to training data\n",
    "assert json_path_train.is_file(), 'training file not found!'\n",
    "f = open(json_path_train)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Annotations for Photometric and Geometric Transformations\n",
    "## [In Progress of Editing] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ocean_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5cde27d6a4ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mimage_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'XYd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mimage_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mocean_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'photometric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print(data['_via_img_metadata'][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mwritable_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'regions'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_via_img_metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'regions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ocean_images' is not defined"
     ]
    }
   ],
   "source": [
    "new_annos = []\n",
    "new_dict = {}\n",
    "for i in data['_via_img_metadata']:\n",
    "    image_names = []\n",
    "    image_sizes = []\n",
    "    img_name = i.split('.')[0]\n",
    "    image_names.append(img_name+'s') #Standard: Unchanged Photo or Geo\n",
    "    image_names.append(img_name+'d') #Darker: Unchanged Geo, darkened image\n",
    "    image_names.append(img_name+'b') #Brighter: Unchanged Geo, Brightened Image\n",
    "    image_names.append(img_name+'Xb')\n",
    "    image_names.append(img_name+'Xd')\n",
    "    image_names.append(img_name+'Xs')\n",
    "    image_names.append(img_name+'Yb')\n",
    "    image_names.append(img_name+'Yd')\n",
    "    image_names.append(img_name+'Ys')\n",
    "    image_names.append(img_name+'XYs')\n",
    "    image_names.append(img_name+'XYb')\n",
    "    image_names.append(img_name+'XYd')\n",
    "    for j in image_names:\n",
    "        image_sizes.append(os.path.getsize(Path(root, 'data', 'SEM', 'photometric', j +'.png')))\n",
    "    writable_dict = {'regions': data['_via_img_metadata'][i]['regions']}\n",
    "    with open('temp_dict1.json', 'w') as t:\n",
    "        json.dump(writable_dict, t)\n",
    "    with open('temp_dict2.json', 'w') as t:\n",
    "        json.dump(writable_dict, t)\n",
    "    with open('temp_dict3.json', 'w') as t:\n",
    "        json.dump(writable_dict, t)\n",
    "    with open('temp_dict4.json', 'w') as t:\n",
    "        json.dump(writable_dict, t)\n",
    "    json_temp_path1 = Path('temp_dict1.json')\n",
    "    json_temp1 = open(json_temp_path1)\n",
    "    initial = json.load(json_temp1)\n",
    "    json_temp_path2 = Path('temp_dict2.json')\n",
    "    json_temp2 = open(json_temp_path2)\n",
    "    inverted_x = json.load(json_temp2)\n",
    "    json_temp_path3 = Path('temp_dict3.json')\n",
    "    json_temp3 = open(json_temp_path3)\n",
    "    inverted_y = json.load(json_temp3)\n",
    "    json_temp_path4 = Path('temp_dict4.json')\n",
    "    json_temp4 = open(json_temp_path4)\n",
    "    inverted_xy = json.load(json_temp4)\n",
    "    inverted_x['regions'] = invert_x_y_regions(inverted_x['regions'], 1024, 768, False, True)\n",
    "    inverted_y['regions'] = invert_x_y_regions(inverted_y['regions'], 1024, 768, True, False)\n",
    "    inverted_xy['regions'] = invert_x_y_regions(inverted_xy['regions'], 1024, 768, True, True)\n",
    "    print('-'*30)\n",
    "    for k in range(len(image_names)):\n",
    "        temp_dict = {}\n",
    "        temp_dict['filename'] = image_names[k] + '.png'\n",
    "        temp_dict['size'] = image_sizes[k]\n",
    "        if k < 3:\n",
    "            temp_dict['regions'] = initial['regions']\n",
    "        elif k < 6:\n",
    "            temp_dict['regions'] = inverted_y['regions']\n",
    "        elif k < 9:\n",
    "            temp_dict['regions'] = inverted_x['regions']\n",
    "        elif k < 12:\n",
    "            temp_dict['regions'] = inverted_xy['regions']\n",
    "        new_dict[image_names[k] +'.png' + str(image_sizes[k])] = temp_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(ocean_images + '/satellite_auto_training_v2.6.json', 'w') as f:\n",
    "    json.dump(new_dict, f)\n",
    "#print(\"Number of Images\", str(len(new_annos)))\n",
    "#print(new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Annotations for Geometric Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "new_annos = []\n",
    "new_dict = {}\n",
    "for i in data['_via_img_metadata']:\n",
    "    image_names = []\n",
    "    image_sizes = []\n",
    "    img_name = i.split('.')[0]\n",
    "    image_names.append(img_name)\n",
    "    image_names.append(img_name+'X') #Augmented Over X Axis\n",
    "    image_names.append(img_name+'Y') #Augmented Over y Axis\n",
    "    image_names.append(img_name+'XY')#Augmented Over X and Y Axis\n",
    "    for j in image_names:\n",
    "        image_sizes.append(os.path.getsize(Path(ocean_images, 'geometric', j +'.png')))\n",
    "    #print(data['_via_img_metadata'][i])\n",
    "    writable_dict = {'regions': data['_via_img_metadata'][i]['regions']}\n",
    "    #print(writable_dict)\n",
    "    with open(ocean_images + '/temp_dict1.json', 'w') as t:\n",
    "        json.dump(writable_dict, t)\n",
    "    with open(ocean_images + '/temp_dict2.json', 'w') as t:\n",
    "        json.dump(writable_dict, t)\n",
    "    with open(ocean_images + '/temp_dict3.json', 'w') as t:\n",
    "        json.dump(writable_dict, t)\n",
    "    with open(ocean_images + '/temp_dict4.json', 'w') as t:\n",
    "        json.dump(writable_dict, t)\n",
    "    json_temp_path1 = Path(ocean_images, 'temp_dict1.json')\n",
    "    json_temp1 = open(json_temp_path1)\n",
    "    initial = json.load(json_temp1)\n",
    "    json_temp_path2 = Path(ocean_images, 'temp_dict2.json')\n",
    "    json_temp2 = open(json_temp_path2)\n",
    "    inverted_x = json.load(json_temp2)\n",
    "    json_temp_path3 = Path(ocean_images, 'temp_dict3.json')\n",
    "    json_temp3 = open(json_temp_path3)\n",
    "    inverted_y = json.load(json_temp3)\n",
    "    json_temp_path4 = Path(ocean_images, 'temp_dict4.json')\n",
    "    json_temp4 = open(json_temp_path4)\n",
    "    inverted_xy = json.load(json_temp4)\n",
    "    inverted_x['regions'] = invert_x_y_regions(inverted_x['regions'], 1024, 768, False, True)\n",
    "    inverted_y['regions'] = invert_x_y_regions(inverted_y['regions'], 1024, 768, True, False)\n",
    "    inverted_xy['regions'] = invert_x_y_regions(inverted_xy['regions'], 1024, 768, True, True)\n",
    "    print('-'*30)\n",
    "    for k in range(len(image_names)):\n",
    "        temp_dict = {}\n",
    "        temp_dict['filename'] = image_names[k] + '.png'\n",
    "        temp_dict['size'] = image_sizes[k]\n",
    "        if k == 0:\n",
    "            temp_dict['regions'] = initial['regions']\n",
    "        elif k == 1:\n",
    "            temp_dict['regions'] = inverted_y['regions']\n",
    "        elif k == 2:\n",
    "            temp_dict['regions'] = inverted_x['regions']\n",
    "        elif k == 3:\n",
    "            temp_dict['regions'] = inverted_xy['regions']\n",
    "        new_dict[image_names[k] +'.png' + str(image_sizes[k])] = temp_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(ocean_images + '/satellite_auto_training_v3.6.json', 'w') as f:\n",
    "    json.dump(new_dict, f)\n",
    "#print(\"Number of Images\", str(len(new_annos)))\n",
    "#print(new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Annotations for Photometric Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "new_annos = []\n",
    "new_dict = {}\n",
    "for i in data['_via_img_metadata']:\n",
    "    image_names = []\n",
    "    image_sizes = []\n",
    "    img_name = i.split('.')[0]\n",
    "    image_names.append(img_name+'s') #Unchanged\n",
    "    image_names.append(img_name+'b') #Brightened\n",
    "    image_names.append(img_name+'d') #Darkened\n",
    "    for j in image_names:\n",
    "        image_sizes.append(os.path.getsize(Path(ocean_images, 'photometric', j +'.png')))\n",
    "    print('-'*30)\n",
    "    for k in range(len(image_names)):\n",
    "        temp_dict = {}\n",
    "        temp_dict['filename'] = image_names[k] + '.png'\n",
    "        temp_dict['size'] = image_sizes[k]\n",
    "        temp_dict['regions'] = data['_via_img_metadata'][i]['regions']\n",
    "        new_dict[image_names[k] +'.png' + str(image_sizes[k])] = temp_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(ocean_images + '/satellite_auto_training_v4.6.json', 'w') as f:\n",
    "    json.dump(new_dict, f)\n",
    "#print(\"Number of Images\", str(len(new_annos)))\n",
    "#print(new_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
